{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ltBrxeJA_dJN"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gitpython langchain openai chromadb tiktoken langchain-community"
      ],
      "metadata": {
        "id": "tDNKnjTo_pxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bVle1MiN_dJO"
      },
      "outputs": [],
      "source": [
        "from git import Repo\n",
        "from langchain.text_splitter import Language\n",
        "from langchain.document_loaders.generic import GenericLoader\n",
        "from langchain.document_loaders.parsers import LanguageParser\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationSummaryMemory\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noZLLtkp_dJO"
      },
      "source": [
        "### Clone Github repositories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "E-wlFc8R_dJP",
        "outputId": "b4d35ec7-6a76-414f-ae36-549709515b91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FDp3oEHC_dJQ"
      },
      "outputs": [],
      "source": [
        "!mkdir test_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zyFkkz__dJQ",
        "outputId": "744d79e7-2913-4cb0-923e-4bc0df74a7bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<git.repo.base.Repo '/content/test_repo/.git'>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "repo_path = \"test_repo/\"\n",
        "\n",
        "Repo.clone_from(\"https://github.com/kshitijkutumbe/Visa-Sanction-Prediction-ML.git\", to_path=repo_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "A2B6fKUt_dJQ"
      },
      "outputs": [],
      "source": [
        "repo_path = \"test_repo/\"\n",
        "\n",
        "loader = GenericLoader.from_filesystem(repo_path+'/us_visa_prediction/pipeline',\n",
        "                                        glob = \"**/*\",\n",
        "                                       suffixes=[\".py\"],\n",
        "                                       parser = LanguageParser(language=Language.PYTHON, parser_threshold=500)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Uqt0u2DF_dJQ"
      },
      "outputs": [],
      "source": [
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWLeIe7n_dJQ",
        "outputId": "06c144e3-7f16-4456-ff63-b15fcca1ca9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'test_repo/us_visa_prediction/pipeline/training_pipeline.py', 'language': <Language.PYTHON: 'python'>}, page_content='import sys\\nfrom us_visa_prediction.exception import USvisaException\\nfrom us_visa_prediction.logger import logging\\n\\nfrom us_visa_prediction.components.data_ingestion import DataIngestion\\nfrom us_visa_prediction.components.data_validation import DataValidation\\nfrom us_visa_prediction.components.data_transformation import DataTransformation\\nfrom us_visa_prediction.components.model_trainer import ModelTrainer\\nfrom us_visa_prediction.components.model_evaluation import ModelEvaluation\\nfrom us_visa_prediction.components.model_pusher import ModelPusher\\n\\nfrom us_visa_prediction.entity.config_entity import (DataIngestionConfig,\\n                                          DataValidationConfig,\\n                                          DataTransformationConfig,\\n                                          ModelTrainerConfig,\\n                                          ModelEvaluationConfig,\\n                                          ModelPusherConfig)\\n                                          \\n\\nfrom us_visa_prediction.entity.artifact_entity import (DataIngestionArtifact,\\n                                            DataValidationArtifact,\\n                                            DataTransformationArtifact,\\n                                            ModelTrainerArtifact,\\n                                            ModelEvaluationArtifact,\\n                                            ModelPusherArtifact)\\n\\n\\n\\nclass TrainPipeline:\\n    def __init__(self):\\n        self.data_ingestion_config = DataIngestionConfig()\\n        self.data_validation_config = DataValidationConfig()\\n        self.data_transformation_config = DataTransformationConfig()\\n        self.model_trainer_config = ModelTrainerConfig()\\n        self.model_evaluation_config = ModelEvaluationConfig()\\n        self.model_pusher_config = ModelPusherConfig()\\n\\n\\n    \\n    def start_data_ingestion(self) -> DataIngestionArtifact:\\n        \"\"\"\\n        This method of TrainPipeline class is responsible for starting data ingestion component\\n        \"\"\"\\n        try:\\n            logging.info(\"Entered the start_data_ingestion method of TrainPipeline class\")\\n            logging.info(\"Getting the data from mongodb\")\\n            data_ingestion = DataIngestion(data_ingestion_config=self.data_ingestion_config)\\n            data_ingestion_artifact = data_ingestion.initiate_data_ingestion()\\n            logging.info(\"Got the train_set and test_set from mongodb\")\\n            logging.info(\\n                \"Exited the start_data_ingestion method of TrainPipeline class\"\\n            )\\n            return data_ingestion_artifact\\n        except Exception as e:\\n            raise USvisaException(e, sys) from e\\n        \\n    \\n\\n    def start_data_validation(self, data_ingestion_artifact: DataIngestionArtifact) -> DataValidationArtifact:\\n        \"\"\"\\n        This method of TrainPipeline class is responsible for starting data validation component\\n        \"\"\"\\n        logging.info(\"Entered the start_data_validation method of TrainPipeline class\")\\n\\n        try:\\n            data_validation = DataValidation(data_ingestion_artifact=data_ingestion_artifact,\\n                                             data_validation_config=self.data_validation_config\\n                                             )\\n\\n            data_validation_artifact = data_validation.initiate_data_validation()\\n\\n            logging.info(\"Performed the data validation operation\")\\n\\n            logging.info(\\n                \"Exited the start_data_validation method of TrainPipeline class\"\\n            )\\n\\n            return data_validation_artifact\\n\\n        except Exception as e:\\n            raise USvisaException(e, sys) from e\\n        \\n\\n\\n    \\n\\n    def start_data_transformation(self, data_ingestion_artifact: DataIngestionArtifact, data_validation_artifact: DataValidationArtifact) -> DataTransformationArtifact:\\n        \"\"\"\\n        This method of TrainPipeline class is responsible for starting data transformation component\\n        \"\"\"\\n        try:\\n            data_transformation = DataTransformation(data_ingestion_artifact=data_ingestion_artifact,\\n                                                     data_transformation_config=self.data_transformation_config,\\n                                                     data_validation_artifact=data_validation_artifact)\\n            data_transformation_artifact = data_transformation.initiate_data_transformation()\\n            return data_transformation_artifact\\n        except Exception as e:\\n            raise USvisaException(e, sys)\\n        \\n\\n    \\n    def start_model_trainer(self, data_transformation_artifact: DataTransformationArtifact) -> ModelTrainerArtifact:\\n        \"\"\"\\n        This method of TrainPipeline class is responsible for starting model training\\n        \"\"\"\\n        try:\\n            model_trainer = ModelTrainer(data_transformation_artifact=data_transformation_artifact,\\n                                         model_trainer_config=self.model_trainer_config\\n                                         )\\n            model_trainer_artifact = model_trainer.initiate_model_trainer()\\n            return model_trainer_artifact\\n\\n        except Exception as e:\\n            raise USvisaException(e, sys)\\n        \\n    \\n\\n    def start_model_evaluation(self, data_ingestion_artifact: DataIngestionArtifact,\\n                               model_trainer_artifact: ModelTrainerArtifact) -> ModelEvaluationArtifact:\\n        \"\"\"\\n        This method of TrainPipeline class is responsible for starting modle evaluation\\n        \"\"\"\\n        try:\\n            model_evaluation = ModelEvaluation(model_eval_config=self.model_evaluation_config,\\n                                               data_ingestion_artifact=data_ingestion_artifact,\\n                                               model_trainer_artifact=model_trainer_artifact)\\n            model_evaluation_artifact = model_evaluation.initiate_model_evaluation()\\n            return model_evaluation_artifact\\n        except Exception as e:\\n            raise USvisaException(e, sys)\\n        \\n\\n    \\n\\n    def start_model_pusher(self, model_evaluation_artifact: ModelEvaluationArtifact) -> ModelPusherArtifact:\\n        \"\"\"\\n        This method of TrainPipeline class is responsible for starting model pushing\\n        \"\"\"\\n        try:\\n            model_pusher = ModelPusher(model_evaluation_artifact=model_evaluation_artifact,\\n                                       model_pusher_config=self.model_pusher_config\\n                                       )\\n            model_pusher_artifact = model_pusher.initiate_model_pusher()\\n            return model_pusher_artifact\\n        except Exception as e:\\n            raise USvisaException(e, sys)\\n\\n        \\n\\n    \\n\\n        \\n\\n    \\n    def run_pipeline(self, ) -> None:\\n        \"\"\"\\n        This method of TrainPipeline class is responsible for running complete pipeline\\n        \"\"\"\\n        try:\\n            data_ingestion_artifact = self.start_data_ingestion()\\n            data_validation_artifact = self.start_data_validation(data_ingestion_artifact=data_ingestion_artifact)\\n            data_transformation_artifact = self.start_data_transformation(\\n                data_ingestion_artifact=data_ingestion_artifact, data_validation_artifact=data_validation_artifact)\\n            model_trainer_artifact = self.start_model_trainer(data_transformation_artifact=data_transformation_artifact)\\n            model_evaluation_artifact = self.start_model_evaluation(data_ingestion_artifact=data_ingestion_artifact,\\n                                                                    model_trainer_artifact=model_trainer_artifact)\\n            \\n            if not model_evaluation_artifact.is_model_accepted:\\n                logging.info(f\"Model not accepted.\")\\n                return None\\n            model_pusher_artifact = self.start_model_pusher(model_evaluation_artifact=model_evaluation_artifact)\\n\\n\\n        \\n        except Exception as e:\\n            raise USvisaException(e, sys)\\n'),\n",
              " Document(metadata={'source': 'test_repo/us_visa_prediction/pipeline/__init__.py', 'language': <Language.PYTHON: 'python'>}, page_content=''),\n",
              " Document(metadata={'source': 'test_repo/us_visa_prediction/pipeline/prediction_pipeline.py', 'language': <Language.PYTHON: 'python'>}, page_content='\\nimport os\\nimport sys\\n\\nimport numpy as np\\nimport pandas as pd\\nfrom us_visa_prediction.entity.config_entity import USvisaPredictorConfig\\nfrom us_visa_prediction.entity.s3_estimator import USvisaEstimator\\nfrom us_visa_prediction.exception import USvisaException\\nfrom us_visa_prediction.logger import logging\\nfrom us_visa_prediction.utils.main_utils import read_yaml_file\\nfrom pandas import DataFrame\\n\\n\\nclass USvisaData:\\n    def __init__(self,\\n                continent,\\n                education_of_employee,\\n                has_job_experience,\\n                requires_job_training,\\n                no_of_employees,\\n                region_of_employment,\\n                prevailing_wage,\\n                unit_of_wage,\\n                full_time_position,\\n                company_age\\n                ):\\n        \"\"\"\\n        Usvisa Data constructor\\n        Input: all features of the trained model for prediction\\n        \"\"\"\\n        try:\\n            self.continent = continent\\n            self.education_of_employee = education_of_employee\\n            self.has_job_experience = has_job_experience\\n            self.requires_job_training = requires_job_training\\n            self.no_of_employees = no_of_employees\\n            self.region_of_employment = region_of_employment\\n            self.prevailing_wage = prevailing_wage\\n            self.unit_of_wage = unit_of_wage\\n            self.full_time_position = full_time_position\\n            self.company_age = company_age\\n\\n\\n        except Exception as e:\\n            raise USvisaException(e, sys) from e\\n\\n    def get_usvisa_input_data_frame(self)-> DataFrame:\\n        \"\"\"\\n        This function returns a DataFrame from USvisaData class input\\n        \"\"\"\\n        try:\\n            \\n            usvisa_input_dict = self.get_usvisa_data_as_dict()\\n            return DataFrame(usvisa_input_dict)\\n        \\n        except Exception as e:\\n            raise USvisaException(e, sys) from e\\n\\n\\n    def get_usvisa_data_as_dict(self):\\n        \"\"\"\\n        This function returns a dictionary from USvisaData class input \\n        \"\"\"\\n        logging.info(\"Entered get_usvisa_data_as_dict method as USvisaData class\")\\n\\n        try:\\n            input_data = {\\n                \"continent\": [self.continent],\\n                \"education_of_employee\": [self.education_of_employee],\\n                \"has_job_experience\": [self.has_job_experience],\\n                \"requires_job_training\": [self.requires_job_training],\\n                \"no_of_employees\": [self.no_of_employees],\\n                \"region_of_employment\": [self.region_of_employment],\\n                \"prevailing_wage\": [self.prevailing_wage],\\n                \"unit_of_wage\": [self.unit_of_wage],\\n                \"full_time_position\": [self.full_time_position],\\n                \"company_age\": [self.company_age],\\n            }\\n\\n            logging.info(\"Created usvisa data dict\")\\n\\n            logging.info(\"Exited get_usvisa_data_as_dict method as USvisaData class\")\\n\\n            return input_data\\n\\n        except Exception as e:\\n            raise USvisaException(e, sys) from e\\n\\nclass USvisaClassifier:\\n    def __init__(self,prediction_pipeline_config: USvisaPredictorConfig = USvisaPredictorConfig(),) -> None:\\n        \"\"\"\\n        :param prediction_pipeline_config: Configuration for prediction the value\\n        \"\"\"\\n        try:\\n            # self.schema_config = read_yaml_file(SCHEMA_FILE_PATH)\\n            self.prediction_pipeline_config = prediction_pipeline_config\\n        except Exception as e:\\n            raise USvisaException(e, sys)\\n\\n    def predict(self, dataframe) -> str:\\n        \"\"\"\\n        This is the method of USvisaClassifier\\n        Returns: Prediction in string format\\n        \"\"\"\\n        try:\\n            logging.info(\"Entered predict method of USvisaClassifier class\")\\n            model = USvisaEstimator(\\n                bucket_name=self.prediction_pipeline_config.model_bucket_name,\\n                model_path=self.prediction_pipeline_config.model_file_path,\\n            )\\n            result =  model.predict(dataframe)\\n            \\n            return result\\n        \\n        except Exception as e:\\n            raise USvisaException(e, sys)\\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNy4ehOX_dJQ"
      },
      "source": [
        "### Chunkings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZTOVGQ68_dJR"
      },
      "outputs": [],
      "source": [
        "documents_splitter = RecursiveCharacterTextSplitter.from_language(language = Language.PYTHON,\n",
        "                                                             chunk_size = 2000,\n",
        "                                                             chunk_overlap = 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5KJo1TGf_dJR"
      },
      "outputs": [],
      "source": [
        "texts = documents_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbOhHleh_dJR",
        "outputId": "4ac792d6-d2eb-4fde-b633-9c89fa97b73d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stQBJ9ItCF-R",
        "outputId": "86d17410-a0fa-4db0-cd0e-ad29677e5409"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'test_repo/us_visa_prediction/pipeline/training_pipeline.py', 'language': <Language.PYTHON: 'python'>}, page_content='import sys\\nfrom us_visa_prediction.exception import USvisaException\\nfrom us_visa_prediction.logger import logging\\n\\nfrom us_visa_prediction.components.data_ingestion import DataIngestion\\nfrom us_visa_prediction.components.data_validation import DataValidation\\nfrom us_visa_prediction.components.data_transformation import DataTransformation\\nfrom us_visa_prediction.components.model_trainer import ModelTrainer\\nfrom us_visa_prediction.components.model_evaluation import ModelEvaluation\\nfrom us_visa_prediction.components.model_pusher import ModelPusher\\n\\nfrom us_visa_prediction.entity.config_entity import (DataIngestionConfig,\\n                                          DataValidationConfig,\\n                                          DataTransformationConfig,\\n                                          ModelTrainerConfig,\\n                                          ModelEvaluationConfig,\\n                                          ModelPusherConfig)\\n                                          \\n\\nfrom us_visa_prediction.entity.artifact_entity import (DataIngestionArtifact,\\n                                            DataValidationArtifact,\\n                                            DataTransformationArtifact,\\n                                            ModelTrainerArtifact,\\n                                            ModelEvaluationArtifact,\\n                                            ModelPusherArtifact)')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8hEeT-8_dJR"
      },
      "source": [
        "### Embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfanb2i8_dJR",
        "outputId": "c293583f-ef31-4708-c527-9910e7e71a66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGGzdVOa_dJR",
        "outputId": "57d0a933-adce-4427-96a8-8b9aef499d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "embeddings=OpenAIEmbeddings(disallowed_special=())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHClBDdJ_dJR"
      },
      "source": [
        "### Knowledge base (vector DB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSF4Dh1X_dJR",
        "outputId": "33f839ed-5855-4b20-b552-d9abd282f300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "vectordb = Chroma.from_documents(texts, embedding=embeddings, persist_directory='./data')\n",
        "vectordb.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZtY7EwB_dJR"
      },
      "source": [
        "### LLM Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJmAlwA5_dJR",
        "outputId": "580e50f6-9174-443b-d8b3-7652de503628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# llm = ChatOpenAI(model_name=\"gpt-4\")\n",
        "llm = ChatOpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9En1USzO_dJR"
      },
      "outputs": [],
      "source": [
        "memory = ConversationSummaryMemory(llm=llm, memory_key = \"chat_history\", return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hSYTwX5p_dJR"
      },
      "outputs": [],
      "source": [
        "\n",
        "qa = ConversationalRetrievalChain.from_llm(llm, retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":3}), memory=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGdhaLX__dJR"
      },
      "source": [
        "### Q&A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1_y0VxZL_dJR"
      },
      "outputs": [],
      "source": [
        "question = \"what is happening in training pipeline?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW6Cz0PE_dJR",
        "outputId": "9a69a947-bee2-41c1-966c-650e4b14a79e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the training pipeline, the following steps are executed:\n",
            "\n",
            "1. Data ingestion is started to bring in the necessary data.\n",
            "2. Data validation is performed on the ingested data.\n",
            "3. Data transformation is carried out on the validated data.\n",
            "4. Model training is initiated using the transformed data.\n",
            "5. Model evaluation is started to evaluate the trained model.\n",
            "6. If the model is not accepted during evaluation, a message is logged and the process stops.\n",
            "7. If the model is accepted, model pushing is started to push the model to a destination.\n",
            "\n",
            "Each step in the pipeline is handled by specific methods in the `TrainPipeline` class, such as `start_data_ingestion()`, `start_data_validation()`, `start_data_transformation()`, `start_model_trainer()`, `start_model_evaluation()`, and `start_model_pusher()`. If any exception occurs during these steps, it is caught and handled by raising a `USvisaException`.\n"
          ]
        }
      ],
      "source": [
        "result = qa(question)\n",
        "print(result['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7oMEPbT_dJS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llmapp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}